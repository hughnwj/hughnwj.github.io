<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>2.Agent实战基础之大模型基础</title>
      <link href="/2025/03/15/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/"/>
      <url>/2025/03/15/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="Agent实战基础之大模型基础"><a href="#Agent实战基础之大模型基础" class="headerlink" title="Agent实战基础之大模型基础"></a>Agent实战基础之大模型基础</h1><h2 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h2><p><img src="/images/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/image-20250315135636248.png" alt="image-20250315135636248"></p><h3 id="输入部分"><a href="#输入部分" class="headerlink" title="输入部分"></a>输入部分</h3><p><img src="/images/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/image-20250315135837941.png" alt="image-20250315135837941"></p><p><strong>框架：</strong></p><ol><li><strong>源文本</strong>：嵌入层以及位置编码器</li><li><strong>目标文本</strong>：嵌入层以及位置编码器</li></ol><p><strong>组件：</strong></p><h4 id="文本嵌入层-Embedding"><a href="#文本嵌入层-Embedding" class="headerlink" title="文本嵌入层 (Embedding)"></a>文本嵌入层 (Embedding)</h4><ul><li><p><strong>概念：</strong><br>文本嵌入层用于将离散的词或符号转化为连续的向量表示，使得每个词都拥有一个固定长度的语义表示。</p></li><li><p><strong>作用：</strong>  </p><ul><li>将词汇转换为低维向量，便于后续的计算处理。  </li><li>捕获词与词之间的语义关系，为模型理解文本提供基础信息。</li></ul></li></ul><h4 id="位置编码器-Positional-Encoding"><a href="#位置编码器-Positional-Encoding" class="headerlink" title="位置编码器 (Positional Encoding)"></a>位置编码器 (Positional Encoding)</h4><ul><li><p><strong>概念：</strong><br>位置编码器为嵌入向量添加位置信息，由于嵌入层本身不包含词序信息，位置编码器弥补了这一不足。</p></li><li><p><strong>作用：</strong>  </p><ul><li>注入序列中各词的相对或绝对位置信息，帮助模型识别词序。  </li><li>保持语法结构，确保模型理解句子内部的依赖关系。</li></ul></li></ul><h3 id="输出部分"><a href="#输出部分" class="headerlink" title="输出部分"></a>输出部分</h3><p><img src="/images/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/image-20250315140112908.png" alt="image-20250315140112908"></p><p><strong>框架：</strong></p><ol><li>线性层  </li><li>softmax 处理器</li></ol><h3 id="解码器部分"><a href="#解码器部分" class="headerlink" title="解码器部分"></a>解码器部分</h3><p><img src="/images/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/image-20250315140122384.png" alt="image-20250315140122384"></p><p><strong>框架：</strong></p><ol><li>由 N 个编码器堆叠  </li><li>每个编码器包含两个子层：<ul><li><strong>第一个子层：</strong> 多头自注意力子层 + 规范化层 + 残差连接  </li><li><strong>第二个子层：</strong> 前馈全连接子层 + 规范化层 + 残差连接</li></ul></li></ol><p><strong>组件：</strong></p><h4 id="掩码张量-mask"><a href="#掩码张量-mask" class="headerlink" title="掩码张量 (mask)"></a>掩码张量 (mask)</h4><ul><li><p><strong>概念：</strong><br>掩码张量用于屏蔽掉不应参与计算的信息，例如填充符号或在生成任务中需要屏蔽未来的信息。</p></li><li><p><strong>作用：</strong>  </p><ul><li>防止模型在计算注意力分数时考虑到无关或不允许访问的信息。  </li><li>确保训练过程中的因果关系（例如在自回归生成模型中屏蔽未来时刻）。</li></ul></li></ul><h4 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h4><p><img src="/images/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/image-20250315143826474.png" alt="image-20250315143826474"></p><p>$$<br>\text{Attention}(Q, K, V) &#x3D; \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \right) V<br>$$</p><ul><li><p><strong>概念：</strong><br>自注意力机制允许模型在计算当前词的表示时，同时考虑序列中所有其他位置的词，从而捕捉全局依赖关系。</p></li><li><p><strong>作用：</strong>  </p><ul><li>动态调整每个词在整体语义表示中的权重。  </li><li>提升模型对长距离依赖关系的捕捉能力。</li></ul></li></ul><blockquote><p><strong>说明：</strong> 输入的 Q、K、V 通常中，K 与 V 是相同的，而 Q 可以不同；特殊情况下 Q&#x3D;K&#x3D;V 则称为标准的自注意力机制。</p></blockquote><h4 id="多头注意力机制"><a href="#多头注意力机制" class="headerlink" title="多头注意力机制"></a>多头注意力机制</h4><p><img src="/images/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/image-20250315144535063.png" alt="image-20250315144535063"></p><ul><li><p><strong>概念：</strong><br>多头注意力机制通过将输入的特征向量划分为多个子空间（head），在每个子空间上分别计算注意力，然后将结果合并，获得更丰富的表示。</p></li><li><p><strong>作用：</strong>  </p><ul><li>使模型能在不同的子空间中捕捉多种语义信息。  </li><li>增强模型的表达能力和稳定性，避免单一注意力头的局限性。</li></ul></li></ul><h4 id="前馈全连接层"><a href="#前馈全连接层" class="headerlink" title="前馈全连接层"></a>前馈全连接层</h4><ul><li><p><strong>概念：</strong><br>前馈全连接层通常由两层线性变换及其中间的非线性激活函数（如 ReLU 或 GeLU）构成，针对每个序列位置独立操作。</p></li><li><p><strong>作用：</strong>  </p><ul><li>进一步提取并组合特征信息，提升模型的非线性表达能力。  </li><li>对每个位置的表示进行独立变换，增强特征的抽象性。</li></ul></li></ul><h4 id="规范化层"><a href="#规范化层" class="headerlink" title="规范化层"></a>规范化层</h4><ul><li><p><strong>概念：</strong><br>规范化层（例如 Layer Normalization）用于对输入特征进行标准化处理，使得数据分布更均匀稳定。</p></li><li><p><strong>作用：</strong>  </p><ul><li>加速模型训练收敛，防止梯度爆炸或消失。  </li><li>保证各层输出处于合理的数值范围内，提高整体稳定性。</li></ul></li></ul><h4 id="残差连接"><a href="#残差连接" class="headerlink" title="残差连接"></a>残差连接</h4><ul><li><p><strong>概念：</strong><br>残差连接（Residual Connection）通过将输入直接加到输出上，形成捷径，帮助缓解深层网络中的梯度消失问题。</p></li><li><p><strong>作用：</strong>  </p><ul><li>促进深层网络中信息的传递。  </li><li>提升训练效率，使得网络在堆叠多层后仍能保持良好性能。</li></ul></li></ul><h3 id="编码器部分"><a href="#编码器部分" class="headerlink" title="编码器部分"></a>编码器部分</h3><p><img src="/images/2.Agent%E5%AE%9E%E6%88%98%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/image-20250315140132700.png" alt="image-20250315140132700"></p><p><strong>框架：</strong></p><ol><li>由 N 个解码器堆叠  </li><li>每个编码器包含三个子层：<ul><li><strong>第一个子层：</strong> 多头自注意力子层 + 规范化层 + 残差连接  </li><li><strong>第二个子层：</strong> 多头注意力子层 + 规范化层 + 残差连接  </li><li><strong>第三个子层：</strong> 前馈全连接子层 + 规范化层 + 残差连接</li></ul></li></ol><h2 id="Open-GPT不同版本对比"><a href="#Open-GPT不同版本对比" class="headerlink" title="Open GPT不同版本对比"></a>Open GPT不同版本对比</h2><h3 id="不同模型对比"><a href="#不同模型对比" class="headerlink" title="不同模型对比"></a>不同模型对比</h3><table><thead><tr><th><strong>模型</strong></th><th><strong>结构</strong></th><th><strong>位置编码</strong></th><th><strong>激活函数</strong></th><th><strong>Layer Norm方法</strong></th></tr></thead><tbody><tr><td>原生</td><td>Encoder-Decoder</td><td>Sinusoidal编码</td><td>ReLU</td><td>Post Layer Norm</td></tr><tr><td>Transformer</td><td>Encoder-Decoder</td><td>Sinusoidal编码</td><td>ReLU</td><td>Post Layer Norm</td></tr><tr><td>BERT</td><td>Encoder</td><td>绝对位置编码</td><td>GeLU</td><td>Post Layer Norm</td></tr><tr><td>LLaMA</td><td>Casual Decoder</td><td>RoPE</td><td>SwiGLU</td><td>Pre RMS Norm</td></tr><tr><td>ChatGLM-6B</td><td>Prefix Decoder</td><td>RoPE</td><td>GeGLU</td><td>Post Deep Norm</td></tr><tr><td>Bloom</td><td>Casual Decoder</td><td>ALiBi</td><td>GeLU</td><td>Pre Layer Norm</td></tr></tbody></table><h3 id="GPT不同版本对比"><a href="#GPT不同版本对比" class="headerlink" title="GPT不同版本对比"></a>GPT不同版本对比</h3><table><thead><tr><th><strong>对比维度</strong></th><th><strong>GPT1</strong></th><th><strong>GPT2</strong></th><th><strong>GPT3</strong></th><th><strong>GPT3.5</strong></th><th><strong>GPT4.0</strong></th></tr></thead><tbody><tr><td><strong>模型规模</strong></td><td>117M</td><td>1.5B</td><td>175B</td><td>175B</td><td>万亿级别</td></tr><tr><td><strong>Transformer层数</strong></td><td>12</td><td>48</td><td>96</td><td>96</td><td>120</td></tr><tr><td><strong>预训练数据集</strong></td><td>Books1, 英语维基百科</td><td>Books1&#x2F;2, 英语维基百科, Web Text2, Common Crawl</td><td>大量的互联网文本，如维基百科、新闻、小说、博客等</td><td>未公开</td><td>未公开</td></tr><tr><td><strong>主要贡献</strong></td><td>1) 提出了基于生成式预训练的语言理解方法</td><td>1) 提出了无监督多任务学习的语言模型</td><td>1) 引入了少样本学习的能力</td><td>发布了全世界顶级的产品，ChatGPT, 让全世界都认识大模型</td><td>1) 展示了预训练和训练数据集规模对模型性能的影响</td></tr><tr><td></td><td>2) 扩展了模型规模</td><td>2) 提出了prompt engineering</td><td>2) 展示了预训练和训练数据集规模对模型性能的提升</td><td>3) 进一步增大了模型规模和训练数据集规模</td><td>2) 展示了大模型在多种下游任务上的性能提升</td></tr><tr><td><strong>发布日期</strong></td><td>2018年</td><td>2019年</td><td>2020年</td><td>2022年</td><td>2023年</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> AI大模型开发工程师 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工作 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.AI大模型应用开发工程师课程导读</title>
      <link href="/2025/03/14/1.AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88%E8%AF%BE%E7%A8%8B%E5%AF%BC%E8%AF%BB/"/>
      <url>/2025/03/14/1.AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88%E8%AF%BE%E7%A8%8B%E5%AF%BC%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="AI大模型应用开发工程师课程导读"><a href="#AI大模型应用开发工程师课程导读" class="headerlink" title="AI大模型应用开发工程师课程导读"></a>AI大模型应用开发工程师课程导读</h1><h3 id="🎯-第一阶段：打好基础"><a href="#🎯-第一阶段：打好基础" class="headerlink" title="🎯 第一阶段：打好基础"></a>🎯 <strong>第一阶段：打好基础</strong></h3><p><strong>目标</strong>：理解大模型基础知识，掌握Agent开发核心概念和工具<br> 📌 <strong>课程模块</strong>：</p><ol><li>AI大模型应用开发工程师课程导读</li><li>Agent实战基础之大模型基础</li><li>Agent实战基础之在线大模型开发</li><li>Agent实战基础之提示词工程和Function进阶实战</li></ol><p>✅ <strong>学习成果</strong>：</p><ul><li>熟悉大模型概念、原理和开发环境</li><li>掌握提示词工程、Function调用，提高模型交互能力</li></ul><hr><h3 id="🚀-第二阶段：强化多模态与Agent架构实战"><a href="#🚀-第二阶段：强化多模态与Agent架构实战" class="headerlink" title="🚀 第二阶段：强化多模态与Agent架构实战"></a>🚀 <strong>第二阶段：强化多模态与Agent架构实战</strong></h3><p><strong>目标</strong>：掌握多模态大模型开发，熟悉Agent架构与落地方案<br> 📌 <strong>课程模块</strong>： 5. Agent实战基础之多模态大模型实战</p><ol start="6"><li>Agent实战基础之Agent架构与落地方案</li><li>Agent实战基础之ReAct架构实战</li></ol><p>✅ <strong>学习成果</strong>：</p><ul><li>理解多模态大模型（图像、文本、语音）融合开发</li><li>熟悉Agent架构（传统+ReAct思路），掌握多场景落地实现</li></ul><hr><h3 id="🔧-第三阶段：进阶开发技能强化"><a href="#🔧-第三阶段：进阶开发技能强化" class="headerlink" title="🔧 第三阶段：进阶开发技能强化"></a>🔧 <strong>第三阶段：进阶开发技能强化</strong></h3><p><strong>目标</strong>：熟练掌握核心工具链，提升开发效率和应用能力<br> 📌 <strong>课程模块</strong>： </p><ol start="8"><li><p>Agent实战技能之Dify智能应用开发</p></li><li><p>Agent实战技能之Assistants API</p></li><li><p>Agent实战技能之LangChain全面剖析</p></li><li><p>Agent实战技能之LangGraph深度实战</p></li></ol><p>✅ <strong>学习成果</strong>：</p><ul><li>上手Dify等智能应用开发平台</li><li>深入掌握LangChain、LangGraph，实现复杂业务逻辑编排</li></ul><hr><h3 id="🏗️-第四阶段：大型项目实战演练"><a href="#🏗️-第四阶段：大型项目实战演练" class="headerlink" title="🏗️ 第四阶段：大型项目实战演练"></a>🏗️ <strong>第四阶段：大型项目实战演练</strong></h3><p><strong>目标</strong>：完成从0到1的大型商业项目开发，积累实战经验<br> 📌 <strong>课程模块</strong>： </p><ol start="12"><li><p>Agent大型项目实战1:百亿级智能数据分析平台</p></li><li><p>Agent大型项目实战2:多模态Agent商业平台</p></li><li><p>Agent大型项目实战3:ChatBI即席查询平台</p></li></ol><p>✅ <strong>学习成果</strong>：</p><ul><li>具备大规模数据分析平台搭建能力</li><li>熟悉多模态Agent在商业场景落地开发</li><li>掌握ChatBI查询平台的完整设计与实现</li></ul><hr><h3 id="🧠-第五阶段：RAG架构与性能优化突破"><a href="#🧠-第五阶段：RAG架构与性能优化突破" class="headerlink" title="🧠 第五阶段：RAG架构与性能优化突破"></a>🧠 <strong>第五阶段：RAG架构与性能优化突破</strong></h3><p><strong>目标</strong>：掌握RAG（检索增强生成）技术，解决大模型知识瓶颈<br> 📌 <strong>课程模块</strong>： </p><ol start="15"><li><p>RAG实战基础之RAG架构演进之路</p></li><li><p>RAG实战基础之RAG技术选型</p></li><li><p>RAG实战基础之性能优化</p></li><li><p>RAG实战进阶之GraphRAG实战</p></li><li><p>RAG项目实战:高性能RAG商业项目</p></li></ol><p>✅ <strong>学习成果</strong>：</p><ul><li>理解RAG原理与架构演进</li><li>掌握RAG系统搭建与性能优化策略</li><li>上手GraphRAG进阶玩法，落地高性能RAG项目</li></ul><hr><h3 id="🔥-第六阶段：DeepSeek专题深度研习"><a href="#🔥-第六阶段：DeepSeek专题深度研习" class="headerlink" title="🔥 第六阶段：DeepSeek专题深度研习"></a>🔥 <strong>第六阶段：DeepSeek专题深度研习</strong></h3><p><strong>目标</strong>：深入探索大模型领域最新技术趋势，完成企业级项目交付<br> 📌 <strong>课程模块</strong>： 20. DeepSeek专题之大模型API实战</p><ol start="21"><li>DeepSeek专题之统一多模态模型</li><li>DeepSeek专题之微调行业大模型</li><li>DeepSeek专题之蒸馏专属大模型</li><li>DeepSeek专题之企业级智能体客服项目</li></ol><p>✅ <strong>学习成果</strong>：</p><ul><li>掌握DeepSeek API与多模态模型开发</li><li>理解大模型微调、蒸馏与专属模型打造</li><li>完成企业级智能体客服系统落地</li></ul><hr><p>✨ <strong>🔚 最终成果</strong></p><ul><li>掌握大模型开发全流程，从基础到实战全覆盖</li><li>理解多模态Agent、RAG、DeepSeek等前沿技术</li><li>具备独立开发和交付大型商业项目能力</li></ul>]]></content>
      
      
      <categories>
          
          <category> AI大模型开发工程师 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工作 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
